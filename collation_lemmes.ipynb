{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports JSON, travail sur les lemmes et typologie des variantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On installe pie et on télécharge les modèles latins\n",
    "!pip3 install pie-extended\n",
    "!pie-extended download lasla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe plusieurs bibliothèques, dont celle de pie (pour l'annotations linguistique) et celle de collatex.\n",
    "import collatex\n",
    "import time\n",
    "import json\n",
    "import pie\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.insert(1, 'utils/')\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatisation du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par lemmatiser notre texte; nous allons utiliser les modèles d'annotation produit par Thibault Clérice à partir des données du LASLA (https://github.com/chartes/deucalion-model-lasla). Créons une fonction simple qui appelle Pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(path):\n",
    "    device = \"cpu\"\n",
    "    batch_size = 500\n",
    "    # Le nom du modèle\n",
    "    modele_lemmes = \"models/lasla-plus-lemma.tar\"\n",
    "    modele_pos = \"models/lasla-plus-pos.tar\"\n",
    "    modele = \"models/model.tar\"\n",
    "    cmd = f' pie-extended tag lasla {path} --device {device} --batch_size {batch_size}'\n",
    "    subprocess.run(cmd.split())\n",
    "    print(f\"Texte annoté enregistré sous {path.replace('.txt', '-pie.txt')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons maintenant qu'à appeler notre fonction sur les textes à annoter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize(\"Catullus/TEXT-Bodmer47-1.txt\")\n",
    "lemmatize(\"Catullus/TEXT-O1.txt\")\n",
    "lemmatize(\"Catullus/TEXT-G2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette étape peut être un peu longue; si elle ne fonctionne pas, les textes lemmatisés sont déjà disponibles à l'emplacement adéquat. Voyons la structure d'un des textes annotés:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Catullus/TEXT-G2-pie.txt\", \"r\") as input_text:\n",
    "    print(input_text.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons maintenant à l'étape suivante. Nous voulons pouvoir inclure les annotations linguistiques dans le processus de collation. Pour ce faire, il faut utiliser un format spécifique qu'est le JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structures et avantages du format JSON pour collatex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collatex demande une structure particulière si l'on veut travailler avec des données non formelles (image tirée de la documentation de l'outil)\n",
    "![Données collatex](img/collatex_json.png)\n",
    "\n",
    "Comme on le voit, chaque texte est présenté tokénisé, l'un après l'autre. Il peut contenir des données normalisées (c'est le cas pour l'entrée `n:cat`), qui seront celles prises en compte pour l'alignement. Nous allons donc produire la table pour collatex en utilisant d'abord les **formes** comme référence. Nous pouvons ajouter autant d'information que nécessaire sous ce format; en outre, nous pouvons ainsi aligner en utilisant les des formes normalisées pour améliorer l'alignement.\n",
    "\n",
    "Commençons par importer nos textes lemmatisés, et par les convertir en listes. C'est le rôle de la fonction `import_annotated_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe chacun des textes\n",
    "bodmer_as_list = utils.import_annotated_data(\"Catullus/TEXT-Bodmer47-1-pie.txt\")\n",
    "O1_as_list = utils.import_annotated_data(\"Catullus/TEXT-O1-pie.txt\")\n",
    "G2_as_list = utils.import_annotated_data(\"Catullus/TEXT-G2-pie.txt\")\n",
    "dict_of_text = {\"Bodmer47\": bodmer_as_list, \"O1\": O1_as_list, \"G2\": G2_as_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut maintenant convertir ces listes en un dictionnaire qui convienne à CollateX. La fonction `create_json_input_for_collatex()` s'en charge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input_forms = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"forms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ce que donne le dictionnaire ainsi créé:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_input_forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignements sur les formes, sur les lemmes, sur lemmes+pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tokens du dictionnaire contiennent toutes les informations dont nous aurons besoin par la suite: la forme `t`, la forme normalisée `n`, le lemme `lemma`, la partie du discours `pos`, la morphologie `morph`. On peut maintenant lancer la collation, en commençant par un **alignement sur les formes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_table_forms = collatex.collate(json_input_forms, output=\"html2\", segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table d'alignement sur les formes est de qualité moyenne, on y compte un certain nombre d'erreurs. Comment améliorer l'alignement ? On peut penser à améliorer la *normalisation* des données, en supprimant l'information graphique et grammaticale: c'est ce que fait la lemmatisation. Passons donc à un **alignement sur les lemmes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_input_lemmas = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"lemmas\")\n",
    "result_table_lemmas = collatex.collate(json_input_lemmas, output=\"html2\", segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est meilleur: le début du texte est aligné de façon correcte, mais il reste quelques erreurs. Pouvons nous encore améliorer les résultats? Possiblement, en choisissant d'**aligner sur la concaténation du lemme et de la partie du discours**. De la sorte, en cas de divergence de lemme (variante lexicale), l'outil pourra toujours s'accrocher à la partie du discours, qui restera probablement inchangée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_input_lemmas_pos = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"lemmas+pos\")\n",
    "result_table_lemmas_pos = collatex.collate(json_input_lemmas_pos, output=\"html2\", segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typologie des variantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est cette dernière table d'alignement que nous allons choisir afin de travailler sur les lieux variants et le classement des variantes. Nous allons utiliser la sortie JSON (`output='json'`) proposée par Collatex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "resultat_alignement_collatex = collatex.collate(json_input_lemmas_pos, output='json', segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nous pouvons imprimer ce résultat, qui est difficilement lisible: il contient l'alignement des trois textes, l'un après l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultat_alignement_collatex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons donc tâcher de travailler cette sortie pour classer les lieux variants. Pour ce faire il faut d'abord regrouper toutes les unités d'alignement (= chaque *token* ou mot aligné):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified = utils.simplify_results(resultat_alignement_collatex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On arrive ainsi au résultat suivant (exemple sur la dernière unité d'alignement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(simplified[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est avec ce format de données que nous allons maintenant travailler. La cellule suivante propose une fonction de classification sommaire qui sera ici utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette cellule charge les fonctions principales permettant d'analyser les variantes\n",
    "\n",
    "def check_pos(locus):\n",
    "    all_pos = [witness['pos'] for witness in locus]\n",
    "    print(f\"Vérifions la nature: {all_pos}\")\n",
    "    if all([pos == all_pos[0] for pos in all_pos[1:]]):\n",
    "        print(\"La partie du discours est identique.\")\n",
    "        return {'pos': True}\n",
    "    else:\n",
    "        print(\"Une différence de nature semble apparaître: variante syntaxique ou grammaticale\")\n",
    "        return {'pos': False}\n",
    "\n",
    "\n",
    "def check_morphology(locus):\n",
    "    all_morph = [witness['morph'] for witness in locus]\n",
    "    print(f\"{' vs '.join(all_morph)}\")\n",
    "    if all([morph == all_morph[0] for morph in all_morph[1:]]):\n",
    "        print(\"La morphologie est identique: variante graphique\")\n",
    "        return {'pos': True}\n",
    "    else:\n",
    "        print(\"Une différence de morphologie semble apparaître: variante syntaxique ou grammaticale\")\n",
    "        return {'pos': False}\n",
    "\n",
    "def check_annotations(locus):\n",
    "    all_lemmas = [witness['lemme'] for witness in locus]\n",
    "    print(all_lemmas)\n",
    "    all_lemmas_as_string = \" | \".join(all_lemmas)\n",
    "    print(f\"Vérifions les lemmes: {all_lemmas_as_string}\")\n",
    "    if all([lemma == all_lemmas[0] for lemma in all_lemmas[1:]]):\n",
    "        print(\"Les lemmes sont identiques.\")\n",
    "        return {**check_pos(locus), **{\"lemmas\": True}}\n",
    "    else:\n",
    "        print(\"Les lemmes sont distincts. Variante lexicale\")\n",
    "        return {\"lemmas\": False, \"pos\":\"UNK\"}\n",
    "\n",
    "\n",
    "def analyse_lieux_variants(collatex_output):\n",
    "    results = utils.simplify_results(collatex_output)\n",
    "    # On crée une boucle sur chaque mot aligné\n",
    "    for index, locus in enumerate(results):\n",
    "        print(f\"Unité d'alignement n°{index + 1}.\")\n",
    "        # On commence par comparer les formes\n",
    "        print(f\"Comparons les formes: {' | '.join([witness['forme'] if witness['forme'] != None else 'ø' for witness in locus])}\")\n",
    "        forme_base = locus[0]['forme']\n",
    "        print(f\"La forme base de la comparaison est: {forme_base}\")\n",
    "        # Si toutes les formes sont identiques entre elles, alors il n'y a pas de lieu variant.\n",
    "        if all([witness['forme'] == forme_base for witness in locus]):\n",
    "            print(\"Toutes les formes sont identiques, il n'y a pas de lieu variant.\")\n",
    "            \n",
    "        # Au contraire, s'il y a une divergence formelle, il faut creuser pour voir si il s'agit d'une variante\n",
    "\n",
    "        # Un cas possible est celui de l'omission d'un des témoins\n",
    "        elif any([witness['forme'] == None for witness in locus]):\n",
    "            all_forms = [witness['forme'] for witness in locus if witness['forme'] != None]\n",
    "            all_forms_as_string = \" | \".join(all_forms)\n",
    "            print(f\"On note une omission à cet endroit du texte. \\nVérifions si les autres témoins concordent: {all_forms_as_string}\")\n",
    "            \n",
    "            # Si les autres témoins concordent, il s'agit d'un lieu variant avec omission d'un témoin (ou plus) uniquement\n",
    "            if all([form == all_forms[0] for form in all_forms[1:]]):\n",
    "                print(\"Les autres témoins concordent. Omission\")\n",
    "\n",
    "            # Dans le cas inverse, il faut creuser pour voir s'il s'agit d'une variante\n",
    "            else:\n",
    "                print(\"Les autres témoins discordent dans leur forme\")\n",
    "                locus = [witness for witness in locus if witness['forme'] != None]\n",
    "                # On va appeler une fonction qui vérifie d'abord si les lemmes concordent, puis si les parties du discours concordent.\n",
    "                annotations_check = check_annotations(locus)\n",
    "                # Si les lemmes et les parties du discours sont strictement identiques, nous avons une variante graphique\n",
    "                if annotations_check['pos'] == True and annotations_check['lemmas'] == True:\n",
    "                    print(\"Vérifions la morphologie:\")\n",
    "                    morph_check = check_morphology(locus)\n",
    "        # Même processus que précédemment, mais sans omission.\n",
    "        else:\n",
    "            print(\"Les témoins discordent dans leur forme.\")\n",
    "            check_lemma = check_annotations(locus)\n",
    "            if check_lemma['pos'] == True and check_lemma['lemmas'] == True:\n",
    "                print(\"Vérifions la morphologie:\")\n",
    "                morph_check = check_morphology(locus)\n",
    "            \n",
    "    \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est de comparer successivement la forme, le lemme, la partie du discours et la morphologie des tokens alignés, unités d'alignement après unité d'alignement -- afin de classer les variantes. L'algorithme est fondé sur Camps, Jean-Baptiste, Lucence Ing, et Elena Spadini. « *Collating Medieval Vernacular Texts: Aligning Witnesses, Classifying Variants* », DH2019, Utrecht, 2019, dont est tiré le tableau suivant: \n",
    "![Collating](img/collating_2019.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "analyse_lieux_variants(resultat_alignement_collatex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on le voit, le processus est très sensible à la qualité de l'annotation et de la lemmatisation, qui est lui-même dépendant de la variabilité graphique des témoins; en l'occurrence, le modèle est ici peu performant car il a été entraîné sur des données issues d'éditions: les unités d'alignement 5 et 30 par exemple sont classées comme variantes lexicales, alors qu'elles ne sont que des variantes graphiques (les lemmes ne sont pas correctement attribués). La phase d'annotation lexico-grammaticale est donc fondamentale et les modèles d'annotation doivent être le plus précis possible. \n",
    "\n",
    "On pourrait aller plus loin en précisant la classification pour indiquer des variations dans la modalité, ou la flexion, comme le font Camps et al. \n",
    "\n",
    "Une étape ultérieure serait celle de l'intégration du sémantisme à l'étude des variantes, afin d'identifier les variantes discursives (et/atque dans l'exemple qui nous intéresse consiste en une variante lexicale qui n'est pas significative, par exemple). \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "rise": {
   "scroll": true,
   "theme": "solarized",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports JSON, travail sur les lemmes et typologie des variantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On installe pie\n",
    "! pip3 install pie-extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe plusieurs bibliothèques, dont celle de pie (pour l'annotations linguistique) et celle de collatex.\n",
    "import collatex\n",
    "import time\n",
    "import json\n",
    "import pie\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.insert(1, 'utils/')\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par lemmatiser notre texte; nous allons utiliser les modèles d'annotation produit par Thibault Clérice à partir des donnés du LASLA. Créons une fonction simple qui appelle Pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(path):\n",
    "    device = \"cpu\"\n",
    "    batch_size = 500\n",
    "    # Le nom du modèle\n",
    "    modele_lemmes = \"models/lasla-plus-lemma.tar\"\n",
    "    modele_pos = \"models/lasla-plus-pos.tar\"\n",
    "    modele = \"models/model.tar\"\n",
    "    cmd = f'pie tag --device {device} --batch_size {batch_size} {path} <{modele},lemma,pos,Person,Numb,Tense,Case,Mood>'\n",
    "    subprocess.run(cmd.split())\n",
    "    print(f\"Texte annoté enregistré sous {path.replace('.txt', '-pie.txt')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons maintenant qu'à appeler notre fonction sur les textes à annoter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize(\"Catullus/TEXT-Bodmer47-1.txt\")\n",
    "lemmatize(\"Catullus/TEXT-O1.txt\")\n",
    "lemmatize(\"Catullus/TEXT-G2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que l'annotation a fonctionné sur un des textes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Catullus/TEXT-G2-pie.txt\", \"r\") as input_text:\n",
    "    print(input_text.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela semble avoir marché. Passons à l'étape suivante. Nous voulons pouvoir inclure les annotations linguistiques dans le processus de collation. Pour ce faire, il faut utiliser un format spécifique qu'est le JSON. Nous allons voir comment faire. Nous allons d'abord ouvrir nos fichiers annotés:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structures et avantages du format JSON pour collatex\n",
    "Collatex demande des données au format json dans une structure très particulière (capture et représentation).\n",
    "Nous pouvons ajouter autant d'information que nécessaire sous ce format; en outre, nous pouvons ainsi aligner en utilisant les des formes normalisées pour améliorer l'alignement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe chacun des textes\n",
    "bodmer_as_list = utils.import_annotated_data(\"Catullus/TEXT-Bodmer47-1-pie.txt\")\n",
    "O1_as_list = utils.import_annotated_data(\"Catullus/TEXT-O1-pie.txt\")\n",
    "G2_as_list = utils.import_annotated_data(\"Catullus/TEXT-G2-pie.txt\")\n",
    "dict_of_text = {\"Bodmer47\": bodmer_as_list, \"O1\": O1_as_list, \"G2\": G2_as_list}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est une liste de listes, comme on le voit plus haut. Chaque élément correspond à la forme analysée, avec les différentes analyses (cas, mode, nombre, personne, temps, lemme, partie du discours)\n",
    "\n",
    "Collatex demande une structure particulière si l'on veut travailler avec des données non formelles (image tirée de la documentation de l'outil)\n",
    "![Données collatex](img/collatex_json.png)\n",
    "\n",
    "Comme on le voit, chaque texte est présenté tokénisé, l'un après l'autre. Il peut contenir des données normalisées (c'est le cas pour l'entrée `n:cat`), qui seront celles prises en compte pour l'alignement. Nous allons donc produire la table pour collatex en utilisant d'abord les **formes** comme référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input_forms = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"forms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ce que donne le dictionnaire ainsi créé:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_input_forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant lancer la collation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table_forms = collatex.collate(json_input_forms, output=\"html2\", segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table d'alignement sur les formes est de qualité moyenne, on y compte un certain nombre d'erreurs. Comment améliorer l'alignement ? On peut penser à améliorer la *normalisation* des données, en supprimant l'information graphique et grammaticale: c'est ce que fait la **lemmatisation**. Alignons donc sur les lemmes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input_lemmas = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"pos\")\n",
    "result_table_lemmas = collatex.collate(json_input_lemmas, output=\"html2\", segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est meilleur: le début du texte est aligné de façon correcte, mais il reste quelques erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input_lemmas_pos = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"lemmas+pos\")\n",
    "result_table_lemmas_pos = collatex.collate(json_input_lemmas_pos, output=\"html2\", segmentation=False, near_match=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_input_lemmas_pos = utils.create_json_input_for_collatex(dict_of_text, collate_on=\"lemmas+pos\")\n",
    "result_table_lemmas_pos = collatex.collate(json_input_lemmas_pos, output=\"html2\", segmentation=False, near_match=True)\n",
    "print(result_table_lemmas_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "resultat_json = collatex.collate(json_input_lemmas_pos, output='json', segmentation=False, near_match=True)\n",
    "alignment_results_as_json = json.loads(resultat_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette cellule charge les fonctions principales permettant d'analyser les variantes\n",
    "\n",
    "def check_pos(locus):\n",
    "    all_pos = [witness['pos'] for witness in locus]\n",
    "    print(f\"Vérifions la nature: {all_pos}\")\n",
    "    if all([pos == all_pos[0] for pos in all_pos[1:]]):\n",
    "        print(\"La partie du discours est identique.\")\n",
    "        return {'pos': True}\n",
    "    else:\n",
    "        print(\"Une différence de nature semble apparaître: variante syntaxique ou grammaticale\")\n",
    "        return {'pos': False}\n",
    "\n",
    "\n",
    "def check_morphology(locus):\n",
    "    all_morph = [witness['morph'] for witness in locus]\n",
    "    print(f\"Vérifions la nature: {all_morph}\")\n",
    "    if all([morph == all_morph[0] for morph in all_morph[1:]]):\n",
    "        print(\"La morphologie est identique: variante grammaticale\")\n",
    "        return {'pos': True}\n",
    "    else:\n",
    "        print(\"Une différence de morphologie semble apparaître: variante syntaxique ou grammaticale\")\n",
    "        return {'pos': False}\n",
    "\n",
    "def check_annotations(locus):\n",
    "    all_lemmas = [witness['lemme'] for witness in locus]\n",
    "    print(all_lemmas)\n",
    "    all_lemmas_as_string = \" | \".join(all_lemmas)\n",
    "    print(f\"Vérifions les lemmes: {all_lemmas_as_string}\")\n",
    "    if all([lemma == all_lemmas[0] for lemma in all_lemmas[1:]]):\n",
    "        print(\"Les lemmes sont identiques.\")\n",
    "        return {**check_pos(locus), **{\"lemmas\": True}}\n",
    "    else:\n",
    "        print(\"Les lemmes sont distincts. Variante lexicale\")\n",
    "        return {\"lemmas\": False, \"pos\":\"UNK\"}\n",
    "\n",
    "def simplify_results(alignment_results_as_json):\n",
    "    zipped = list(zip(alignment_results_as_json['table'][0], alignment_results_as_json['table'][1], alignment_results_as_json['table'][2]))\n",
    "\n",
    "    output_data = list()\n",
    "    for locus in zipped:\n",
    "        interm_list = []\n",
    "        for index, witness in enumerate(locus):\n",
    "            if witness is not None:\n",
    "                interm_dict = dict()\n",
    "                interm_dict['témoin'] = witness[0]['_sigil']\n",
    "                interm_dict['forme'] = witness[0]['t']\n",
    "                interm_dict['lemme'] = witness[0]['lemma']\n",
    "                interm_dict['pos'] = witness[0]['pos']\n",
    "                interm_dict['morph'] = witness[0]['morph']\n",
    "                interm_list.append(interm_dict)\n",
    "            else:\n",
    "                interm_dict = dict()\n",
    "                interm_dict['témoin'] = alignment_results_as_json[\"witnesses\"][index]\n",
    "                interm_dict['forme'] = None\n",
    "                interm_dict['lemme'] = None\n",
    "                interm_dict['pos'] = None\n",
    "                interm_dict['morph'] = None\n",
    "                interm_list.append(interm_dict)\n",
    "        output_data.append(interm_list)\n",
    "    return output_data\n",
    "\n",
    "def analyse_lieux_variants(collatex_output):\n",
    "    results = simplify_results(collatex_output)\n",
    "    # On crée une boucle sur chaque mot aligné\n",
    "    for index, locus in enumerate(results):\n",
    "        print(f\"Unité d'alignement n°{index + 1}.\")\n",
    "        # On commence par comparer les formes\n",
    "        print(f\"Comparons les formes: {' | '.join([witness['forme'] if witness['forme'] != None else 'ø' for witness in locus])}\")\n",
    "        forme_base = locus[0]['forme']\n",
    "        print(f\"La forme base de la comparaison est: {forme_base}\")\n",
    "        # Si toutes les formes sont identiques entre elles, alors il n'y a pas de lieu variant.\n",
    "        if all([witness['forme'] == forme_base for witness in locus]):\n",
    "            print(\"Toutes les formes sont identiques, il n'y a pas de lieu variant.\")\n",
    "            \n",
    "        # Au contraire, s'il y a une divergence formelle, il faut creuser pour voir si il s'agit d'une variante\n",
    "\n",
    "        # Un cas possible est celui de l'omission d'un des témoins\n",
    "        elif any([witness['forme'] == None for witness in locus]):\n",
    "            all_forms = [witness['forme'] for witness in locus if witness['forme'] != None]\n",
    "            all_forms_as_string = \" | \".join(all_forms)\n",
    "            print(f\"On note une omission à cet endroit du texte. \\nVérifions si les autres témoins concordent: {all_forms_as_string}\")\n",
    "            \n",
    "            # Si les autres témoins concordent, il s'agit d'un lieu variant avec omission d'un témoin (ou plus) uniquement\n",
    "            if all([form == all_forms[0] for form in all_forms[1:]]):\n",
    "                print(\"Les autres témoins concordent. Omission\")\n",
    "\n",
    "            # Dans le cas inverse, il faut creuser pour voir s'il s'agit d'une variante\n",
    "            else:\n",
    "                print(\"Les autres témoins discordent dans leur forme\")\n",
    "                locus = [witness for witness in locus if witness['forme'] != None]\n",
    "                # On va appeler une fonction qui vérifie d'abord si les lemmes concordent, puis si les parties du discours concordent.\n",
    "                annotations_check = check_annotations(locus)\n",
    "                # Si les lemmes et les parties du discours sont strictement identiques, nous avons une variante graphique\n",
    "                if annotations_check['pos'] == True and annotations_check['lemmas'] == True:\n",
    "                    print(\"Vérifions la morphologie\")\n",
    "                    morph_check = check_morphology(locus)\n",
    "        # Même processus que précédemment, mais sans omission.\n",
    "        else:\n",
    "            print(\"Les témoins discordent dans leur forme.\")\n",
    "            check_lemma = check_annotations(locus)\n",
    "            if check_lemma['pos'] == True and check_lemma['lemmas'] == True:\n",
    "                print(\"Vérifions la morphologie\")\n",
    "                morph_check = check_morphology(locus)\n",
    "            \n",
    "    \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée est de comparer successivement la forme, le lemme, la partie du discours et la morphologie des tokens alignés, unités d'alignement après unité d'alignement -- toutes n'étant pas des lieux variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "analyse_lieux_variants(alignment_results_as_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on le voit, le processus est très sensible à la qualité de l'annotation et de la lemmatisation, qui est lui-même dépendant de la variabilité graphique des témoins; en l'occurrence, le modèle est ici peu performant car il a été entraîné sur des données issues d'éditions: les unités d'alignement 5 et 30 par exemple sont classées comme variantes lexicales, alors qu'elles ne sont que des variantes graphiques (les lemmes ne sont pas correctement attribués).  \n",
    "\n",
    "\n",
    "La phase d'annotation lexico-grammaticale est donc fondamentale et les modèles d'annotation doivent être le plus précis possible; une autre possibilité, que propose Thibault Clérice avec Pie-Extended: (https://pypi.org/project/pie-extended/), est de normaliser la graphie avant d'annoter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "rise": {
   "scroll": true,
   "theme": "solarized",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
